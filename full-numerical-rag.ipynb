{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T18:21:59.838482Z",
     "start_time": "2025-08-19T18:21:30.791579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Numeric-aware RAG with Qdrant: smart query parser for numeric constraints.\n",
    "\n",
    "What this script shows:\n",
    " 1) Create a Qdrant collection with text vectors + numeric payloads\n",
    " 2) Parse natural-language queries for numeric filters (>, <, between, etc.)\n",
    " 3) Combine semantic search (embeddings) with structured numeric filtering\n",
    " 4) (Optional) Handle \"top/bottom N by <field>\" sorting after retrieval\n",
    "\n",
    "Dependencies:\n",
    "    pip install qdrant-client sentence-transformers\n",
    "\n",
    "Notes:\n",
    " - Replace the in-memory client with your persistent Qdrant endpoint.\n",
    " - Customize FIELD_ALIASES to your domain.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, PointStruct, Filter, FieldCondition, Range\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Config & helpers\n",
    "# ---------------------------\n",
    "\n",
    "# Canonical field names -> list of aliases that may appear in user queries\n",
    "FIELD_ALIASES: Dict[str, List[str]] = {\n",
    "    \"gdp_per_capita\": [\"gdp per capita\", \"gdp/capita\", \"gdp pc\", \"gdp per person\", \"gdp\"],\n",
    "    \"population\": [\"population\", \"pop\"],\n",
    "    \"life_expectancy\": [\"life expectancy\", \"lifespan\"],\n",
    "}\n",
    "\n",
    "# You can add categorical fields here if needed, but this example focuses on numeric ranges.\n",
    "\n",
    "SUFFIX_MULTIPLIERS = {\n",
    "    \"k\": 1_000,\n",
    "    \"m\": 1_000_000,\n",
    "    \"b\": 1_000_000_000,\n",
    "    \"t\": 1_000_000_000_000,\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class NumericConstraint:\n",
    "    field: str\n",
    "    gte: Optional[float] = None\n",
    "    lte: Optional[float] = None\n",
    "    gt: Optional[float] = None\n",
    "    lt: Optional[float] = None\n",
    "\n",
    "@dataclass\n",
    "class RankDirective:\n",
    "    direction: str  # 'top' or 'bottom'\n",
    "    n: int\n",
    "    field: str\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Parsing utilities\n",
    "# ---------------------------\n",
    "\n",
    "def normalize_number(token: str) -> Optional[float]:\n",
    "    \"\"\"Convert '50k', '2.5M', '10,000', '$30', '30%' -> float (strip currency/percent).\n",
    "    Returns None if not a number.\n",
    "    \"\"\"\n",
    "    s = token.strip().lower()\n",
    "    s = s.replace(\",\", \"\").replace(\"$\", \"\").replace(\"%\", \"\")\n",
    "    m = re.fullmatch(r\"([0-9]*\\.?[0-9]+)\\s*([kmbt])?\", s)\n",
    "    if not m:\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    value = float(m.group(1))\n",
    "    suf = m.group(2)\n",
    "    if suf:\n",
    "        value *= SUFFIX_MULTIPLIERS[suf]\n",
    "    return value\n",
    "\n",
    "\n",
    "def find_field_in_text(text: str) -> List[Tuple[str, Tuple[int, int]]]:\n",
    "    \"\"\"Return list of (canonical_field, span) for each alias occurrence in text.\"\"\"\n",
    "    out = []\n",
    "    lowered = text.lower()\n",
    "    for field, aliases in FIELD_ALIASES.items():\n",
    "        for alias in aliases:\n",
    "            for m in re.finditer(r\"\\b\" + re.escape(alias) + r\"\\b\", lowered):\n",
    "                out.append((field, m.span()))\n",
    "    # Sort by position in text, deterministic\n",
    "    out.sort(key=lambda x: x[1][0])\n",
    "    return out\n",
    "\n",
    "\n",
    "def parse_rank_directive(query: str) -> Optional[RankDirective]:\n",
    "    \"\"\"Parse patterns like:\n",
    "       - top 5 by gdp per capita\n",
    "       - bottom 10 by population\n",
    "    \"\"\"\n",
    "    q = query.lower()\n",
    "    m = re.search(r\"\\b(top|bottom)\\s+(\\d+)\\s+by\\s+([a-z0-9\\s/]+?)\\b\", q)\n",
    "    if not m:\n",
    "        return None\n",
    "    direction, n_str, field_text = m.groups()\n",
    "    n = int(n_str)\n",
    "    # Map field_text to canonical field\n",
    "    field_text = field_text.strip()\n",
    "    for field, aliases in FIELD_ALIASES.items():\n",
    "        for a in aliases:\n",
    "            if field_text == a:\n",
    "                return RankDirective(direction=direction, n=n, field=field)\n",
    "    # fuzzy: if field_text contains alias\n",
    "    for field, aliases in FIELD_ALIASES.items():\n",
    "        for a in aliases:\n",
    "            if a in field_text:\n",
    "                return RankDirective(direction=direction, n=n, field=field)\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_numeric_constraints(query: str) -> List[NumericConstraint]:\n",
    "    \"\"\"Parse simple numeric constraints tied to fields.\n",
    "\n",
    "    Supported constructs (order-insensitive, near-field matching):\n",
    "      - gdp per capita >= 50k\n",
    "      - population between 1m and 5m\n",
    "      - life expectancy > 70\n",
    "      - under 3k population\n",
    "      - at least 20k gdp\n",
    "      - gdp from 10k to 30k\n",
    "      - no more than 1000 pop\n",
    "\n",
    "    Strategy: detect field mentions and search in a window around each for numeric patterns.\n",
    "    \"\"\"\n",
    "    constraints: Dict[str, NumericConstraint] = {}\n",
    "    q = query.lower()\n",
    "    field_spans = find_field_in_text(q)\n",
    "\n",
    "    # If no explicit fields found, we cannot bind numbers confidently\n",
    "    if not field_spans:\n",
    "        return []\n",
    "\n",
    "    def get_or_make(field: str) -> NumericConstraint:\n",
    "        nc = constraints.get(field)\n",
    "        if not nc:\n",
    "            nc = NumericConstraint(field)\n",
    "            constraints[field] = nc\n",
    "        return nc\n",
    "\n",
    "    WINDOW = 48  # chars around field mention to scan for numbers/operators\n",
    "\n",
    "    # Operator phrases -> (gte, lte, gt, lt)\n",
    "    OPS = [\n",
    "        (r\">=|at least|no less than|minimum of|\\bmin\\b\", \"gte\"),\n",
    "        (r\"<=|at most|no more than|maximum of|\\bmax\\b\", \"lte\"),\n",
    "        (r\">|over|above|more than|exceed(ing)?\", \"gt\"),\n",
    "        (r\"<|under|below|less than|fewer than\", \"lt\"),\n",
    "    ]\n",
    "\n",
    "    for field, (start, end) in field_spans:\n",
    "        left = max(0, start - WINDOW)\n",
    "        right = min(len(q), end + WINDOW)\n",
    "        ctx = q[left:right]\n",
    "\n",
    "        # 1) BETWEEN / FROM ... TO ...\n",
    "        m = re.search(r\"(between|from)\\s+([$0-9.,kmbt%]+)\\s+(and|to)\\s+([$0-9.,kmbt%]+)\", ctx)\n",
    "        if m:\n",
    "            v1 = normalize_number(m.group(2))\n",
    "            v2 = normalize_number(m.group(4))\n",
    "            if v1 is not None and v2 is not None:\n",
    "                low, high = sorted([v1, v2])\n",
    "                nc = get_or_make(field)\n",
    "                nc.gte = low\n",
    "                nc.lte = high\n",
    "\n",
    "        # 2) Simple comparator near a number (e.g., \"> 50k\", \"at least 20m\")\n",
    "        # Scan for number tokens and look behind/ahead for an operator phrase\n",
    "        for num_m in re.finditer(r\"[$0-9.,]+\\s*[kmbt%]?\", ctx):\n",
    "            num_text = num_m.group(0)\n",
    "            value = normalize_number(num_text)\n",
    "            if value is None:\n",
    "                continue\n",
    "            # look behind 12 words, ahead 6 words for an operator phrase\n",
    "            span_left = max(0, num_m.start() - 64)\n",
    "            span_right = min(len(ctx), num_m.end() + 64)\n",
    "            mini = ctx[span_left:span_right]\n",
    "            for pat, key in OPS:\n",
    "                if re.search(pat, mini):\n",
    "                    nc = get_or_make(field)\n",
    "                    setattr(nc, key, value)\n",
    "                    break\n",
    "\n",
    "        # 3) Loose pattern: \"<number> (units) <field>\" like \"under 3m population\" handled above.\n",
    "        # If no op found but exact equals implied like \"gdp 50000\" -> treat as >= and <= same value\n",
    "        if field not in constraints:\n",
    "            # try pattern: field followed by a lone number\n",
    "            m2 = re.search(r\"\\b([$0-9.,]+\\s*[kmbt%]?)\\b\", ctx)\n",
    "            if m2:\n",
    "                value = normalize_number(m2.group(1))\n",
    "                if value is not None:\n",
    "                    nc = get_or_make(field)\n",
    "                    nc.gte = value\n",
    "                    nc.lte = value\n",
    "\n",
    "    return list(constraints.values())\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Demo data + Qdrant setup\n",
    "# ---------------------------\n",
    "\n",
    "def build_demo_collection(client: QdrantClient, model: SentenceTransformer, collection: str = \"countries\"):\n",
    "\n",
    "    # check if collection already exists\n",
    "    if client.collection_exists(collection):\n",
    "        # delete it first (if you want to recreate it)\n",
    "        client.delete_collection(collection)\n",
    "\n",
    "    # now create the collection\n",
    "    client.create_collection(\n",
    "        collection_name = collection,\n",
    "        vectors_config = VectorParams(size=model.get_sentence_embedding_dimension(), distance=\"Cosine\")  # your vector configuration\n",
    "    )\n",
    "\n",
    "    # client.recreate_collection(\n",
    "    #     collection_name=collection,\n",
    "    #     vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(), distance=\"Cosine\"),\n",
    "    # )\n",
    "\n",
    "    docs = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"United States\",\n",
    "            \"gdp_per_capita\": 74000,\n",
    "            \"population\": 331_000_000,\n",
    "            \"life_expectancy\": 77.3,\n",
    "            \"desc\": \"The United States has a highly developed economy with significant innovation.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Japan\",\n",
    "            \"gdp_per_capita\": 42000,\n",
    "            \"population\": 126_000_000,\n",
    "            \"life_expectancy\": 84.6,\n",
    "            \"desc\": \"Japan is known for advanced technology, aging population, and high life expectancy.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"name\": \"India\",\n",
    "            \"gdp_per_capita\": 2700,\n",
    "            \"population\": 1_380_000_000,\n",
    "            \"life_expectancy\": 70.4,\n",
    "            \"desc\": \"India has a rapidly growing economy and very large population.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": 4,\n",
    "            \"name\": \"Norway\",\n",
    "            \"gdp_per_capita\": 89000,\n",
    "            \"population\": 5_400_000,\n",
    "            \"life_expectancy\": 83.2,\n",
    "            \"desc\": \"Norway has one of the highest GDP per capita values and high quality of life.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    points: List[PointStruct] = []\n",
    "    for d in docs:\n",
    "        vec = model.encode(d[\"desc\"]).tolist()\n",
    "        payload = {\n",
    "            \"name\": d[\"name\"],\n",
    "            \"desc\": d[\"desc\"],\n",
    "            \"gdp_per_capita\": d[\"gdp_per_capita\"],\n",
    "            \"population\": d[\"population\"],\n",
    "            \"life_expectancy\": d[\"life_expectancy\"],\n",
    "        }\n",
    "        points.append(PointStruct(id=d[\"id\"], vector=vec, payload=payload))\n",
    "\n",
    "    client.upsert(collection_name=collection, points=points)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Retrieval with numeric filters + optional ranking\n",
    "# ---------------------------\n",
    "\n",
    "def build_qdrant_filter(ncs: List[NumericConstraint]) -> Optional[Filter]:\n",
    "    conds = []\n",
    "    for nc in ncs:\n",
    "        # Build a single Range that may include multiple bounds\n",
    "        r = Range()\n",
    "        if nc.gte is not None:\n",
    "            r.gte = float(nc.gte)\n",
    "        if nc.lte is not None:\n",
    "            r.lte = float(nc.lte)\n",
    "        if nc.gt is not None:\n",
    "            r.gt = float(nc.gt)\n",
    "        if nc.lt is not None:\n",
    "            r.lt = float(nc.lt)\n",
    "        conds.append(FieldCondition(key=nc.field, range=r))\n",
    "    if not conds:\n",
    "        return None\n",
    "    return Filter(must=conds)\n",
    "\n",
    "\n",
    "def search_with_numeric_awareness(\n",
    "    client: QdrantClient,\n",
    "    model: SentenceTransformer,\n",
    "    collection: str,\n",
    "    query: str,\n",
    "    k: int = 8,\n",
    "):\n",
    "    # Parse constraints and rank directive\n",
    "    constraints = parse_numeric_constraints(query)\n",
    "    rank = parse_rank_directive(query)\n",
    "\n",
    "    # Semantic vector\n",
    "    qvec = model.encode(query).tolist()\n",
    "\n",
    "    qfilter = build_qdrant_filter(constraints)\n",
    "\n",
    "    res = client.query_points(\n",
    "        collection_name=collection,\n",
    "        with_vectors=qvec,\n",
    "        limit=k,\n",
    "        query_filter=qfilter,\n",
    "    )\n",
    "\n",
    "    # Optional: post-sort by rank directive\n",
    "    if rank is not None:\n",
    "        field = rank.field\n",
    "        reverse = True if rank.direction == \"top\" else False\n",
    "        res = sorted(\n",
    "            res,\n",
    "            key=lambda r: r.payload.get(field, float(\"nan\")),\n",
    "            reverse=reverse,\n",
    "        )\n",
    "        res = res[: rank.n]\n",
    "\n",
    "    return res, constraints, rank\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Example usage\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    client = QdrantClient(\":memory:\")  # swap for host=..., port=... in real setups\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    build_demo_collection(client, model)\n",
    "\n",
    "    example_queries = [\n",
    "        \"wealthy countries with gdp per capita >= 50k\",\n",
    "        \"countries with population between 1m and 10m\",\n",
    "        \"show top 2 by life expectancy\",\n",
    "        \"high quality of life but under 10m population\",\n",
    "        \"countries with gdp from 40k to 100k\",\n",
    "        \"countries with gdp 89000\",  # equals-ish fallback\n",
    "    ]\n",
    "\n",
    "    for q in example_queries:\n",
    "        hits, ncs, rank = search_with_numeric_awareness(client, model, \"countries\", q, k=10)\n",
    "        print(\"\\nQuery:\", q)\n",
    "        print(\"Parsed constraints:\", ncs)\n",
    "        print(\"Rank directive:\", rank)\n",
    "        print(\"Results:\")\n",
    "        for h in hits.points:\n",
    "            p = h.payload\n",
    "            print(\n",
    "                f\" - {p['name']}: gdp_per_capita={p['gdp_per_capita']}, population={p['population']}, life_expectancy={p['life_expectancy']}\"\n",
    "            )\n",
    "\n",
    "    # You can now pass `hits` payloads as context to your LLM prompt to complete the RAG step.\n"
   ],
   "id": "eabf424cac93b0d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\powen\\PycharmProjects\\LinkedIn-Learning\\venv-3.10.10\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Query: wealthy countries with gdp per capita >= 50k\n",
      "Parsed constraints: [NumericConstraint(field='gdp_per_capita', gte=50000.0, lte=None, gt=None, lt=None)]\n",
      "Rank directive: None\n",
      "Results:\n",
      " - United States: gdp_per_capita=74000, population=331000000, life_expectancy=77.3\n",
      " - Norway: gdp_per_capita=89000, population=5400000, life_expectancy=83.2\n",
      "\n",
      "Query: countries with population between 1m and 10m\n",
      "Parsed constraints: [NumericConstraint(field='population', gte=1000000.0, lte=10000000.0, gt=None, lt=None)]\n",
      "Rank directive: None\n",
      "Results:\n",
      " - Norway: gdp_per_capita=89000, population=5400000, life_expectancy=83.2\n",
      "\n",
      "Query: show top 2 by life expectancy\n",
      "Parsed constraints: [NumericConstraint(field='life_expectancy', gte=2.0, lte=2.0, gt=None, lt=None)]\n",
      "Rank directive: None\n",
      "Results:\n",
      "\n",
      "Query: high quality of life but under 10m population\n",
      "Parsed constraints: [NumericConstraint(field='population', gte=None, lte=None, gt=None, lt=10000000.0)]\n",
      "Rank directive: None\n",
      "Results:\n",
      " - Norway: gdp_per_capita=89000, population=5400000, life_expectancy=83.2\n",
      "\n",
      "Query: countries with gdp from 40k to 100k\n",
      "Parsed constraints: [NumericConstraint(field='gdp_per_capita', gte=40000.0, lte=100000.0, gt=None, lt=None)]\n",
      "Rank directive: None\n",
      "Results:\n",
      " - United States: gdp_per_capita=74000, population=331000000, life_expectancy=77.3\n",
      " - Japan: gdp_per_capita=42000, population=126000000, life_expectancy=84.6\n",
      " - Norway: gdp_per_capita=89000, population=5400000, life_expectancy=83.2\n",
      "\n",
      "Query: countries with gdp 89000\n",
      "Parsed constraints: [NumericConstraint(field='gdp_per_capita', gte=89000.0, lte=89000.0, gt=None, lt=None)]\n",
      "Rank directive: None\n",
      "Results:\n",
      " - Norway: gdp_per_capita=89000, population=5400000, life_expectancy=83.2\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
